

== API Interoperability

=== SOFP WFS3 Weather Server

To gain maximal interoperability, the defined API should be as general as possible. The general parts empower existing libraries and software to communicate with the API. Excessively general design, however, present unnecessary confusion since the API is not intuitive and/or it works inconsistently.

_SOFP WFS3 Weather Server_ were build to fully meet _OGC API - Features Core_ to gain maximal client support and easy access to the data to developers outside the geospatial community. Following challenges and shortcomings in the current standard were identified.

==== Simple Observation Time Series

To request all temperature and humidity observations from a time range inside the given area, the following request could be used:

 GET /datasets/weather/observation/aws/items?
   parametername=Temperature,Humidity
   &time=20181204T150000/20181204T180000
   &bbox=20,60,30,70

The request is _OGC API - Features Core_ compatible except the time definition, which would need an extension. Time range support is widely adopted in a broad range of applications and would be reasonable to define in _OGC API - Features_ standard. However, other time definitions used in many environmental domains such as origin time and lead time are not commonly recognised and would require a domain-specific specification.

==== Resampled Weather Forecast Model Output

To request a weather model output inside some area, following request could be used:

 GET /datasets/weather/forecast/harmonie/items?
   parametername=Temperature,Humidity
   &time=20181204T150000/20181204T180000
   &bbox=20,60,30,70
   &limit=100

The request returns a collection of features containing a resampled regular grid with 100 points (10x10) inside the given bounding box. All features are resampled and generated on-demand based on the request. Smaller bounding box would return more detailed information and a larger one less detailed. The pattern is fully compatible with _OGC API - Features Core_ but may be unintuitive to the users used to handle pre-existing features.

==== Single Point Weather Forecast Model Output

_SOFP WFS3 Weather Server_ allows users to request any single point as well. In those cases, it interpolates the response on-demand to the exact requested location in space and time. The functionality is achieved with a (mis)usage of standard filtering defined in _OGC API - Features Core_:

 GET /datasets/weather/forecast/harmonie/items?
   parametername=Temperature,Humidity
   &time=20181204T150000/20181204T180000
   &bbox=20,60,30,70
   &lat=60.159900&lon=24.876116

The pattern is fully Core-compatible but clients are allowed to request _any_ latitude and longitude inside the data area. The upside of such behaviour is wide client support and the downside is possible obscurity. The functionality can, of course, be described to the developers in OpenAPI definition and API can be extended with query parameters such as _interpolation_method_, but the main concern of the balance between interpretability and clarity remains.

== Data Format

=== OGC Observations and Measurements - Simple Feature model & encodings (OMSF)

TBD

== Other Notes

=== Feature IDs

_OGC API - Features_ standard assumes that all features have a unique identifier, which may be problematic if responses are generated on-demand (for example in _SOFP WFS3 Weather Server_). In case of weather forecasts, IDs can be formed in a unique manner on-demand following:

 parameter:producer:level_type:level:forecast_type:ensemble_number:origin_time:area:time:area_interpolation_method:time_interpolation_method:level_interpolation_method

This convention makes the feature ID to a query language itself, which may be beneficial for power users.

=== Forming Collections

_OGC API - Features_ leaves relatively lot degree of freedom to form collections in different ways. To serve a wide range of domains, this is naturally necessary. In a more specific domain, such as serving weather data, different conventions may be confusing to the end-users. It would be advisable to harmonise at least the following aspects:

- One collection per weather model or one collection per parameter?
- One entry point per organisation or on entry point per dataset (i.e. weather model) or one entry point per data type (i.e. observations/forecast/climatology)?

== Issues identified with the candidate specification during the hackathon 

==== Use the home page / API root as a help / guidance page

Whilst a lot of the information that the users struggled to find was available from the conformance and API endpoints, the terms were new to the users of the API.  A richer set of explanations and descriptions on the API home page would be useful (This was more a limitation of prototype than the specification).

==== Better descriptions for the meanings of Group/Collection/Instance

Another artefact of an API that is abstracting the user from the underlying source is that the aggregation terms by their nature have little to do with the data itself.  It is therefore essential that the returned information provides an explanation of the reasons and meaning of the aggregations. 

- Improve descriptions and use JSON-LD to provide links to more detailed information

==== Easier discovery of available data parameters

Finding the required information proved to be awkward, currently a user has to investigate the metadata for each collection individually to find what information is available via the service.  A ability to search and filter by the information (parameters/features) available would simplify the process, this would also need to return the metadata about any spatial and temporal differences in the parameters. 

- Create groups based on available parameters
- Add an API endpoint for the discovery of parameters
 

==== Ability to filter available collections by spatial/temporal coverage

This functionality was missing from the prototype, but the ability to filter the available collections by time and area was considered important.

- Add time and bbox query parameters to the meteadata queries

==== Custom metadata

A need was identified to be able to return metadata that was specific for a collection type.  Although all users appreciated the ability to utilise the same query patterns and data parsers to handle different types of data, there are occasions when necessary metadata that cannot be mapped to a generic patten.  The instance metadata reponse needs to have a facility to include metadata that does not fit into the generic core response.

- This might be solved by having optional sections based on the structure of the underlying data (i.e. Feature or Coverage).

==== Use of Well Known Text

The use of Well Known Text (WKT) for describing the query coordinates did not cause any issues, but a question was raised about the differences in approach to using WKT between the current API type definitions. Currently the Point and Polygon types do not use WKT for the Time and Level query parameters where as the Trajectory query does.  

Point instance request:
[source]
----
GET /collections/gfs_025_time-height_above_ground-lat-lon/latest/point/coords=POINT(-3.2 51.2)&time=2019-08-25T03:00:00Z&z=2.0&output_format=application/json
----
Point timeseries request:
[source]
----
GET /collections/gfs_025_time-height_above_ground-lat-lon/latest/point/coords=POINT(-3.2 51.2)&time=2019-08-25T03:00:00Z/2019-08-25T15:00:00Z&z=2.0&output_format=application/json
----
Polygon instance request:
[source]
----
GET /collections/gfs_025_time-height_above_ground-lat-lon/latest/polygon/coords=POLYGON((-15 48.8 500,-15 60.95 500,5 60.85 500,5 48.8 500,-15 48.8 500))&time=2019-08-25T03:00:00Z&z=2.0&output_format=application/json
----
Polygon timeseries request:
[source]
----
GET /collections/gfs_025_time-height_above_ground-lat-lon/latest/polygon/coords=POLYGON((-15 48.8 500,-15 60.95 500,5 60.85 500,5 48.8 500,-15 48.8 500))&time=2019-08-25T03:00:00Z/2019-08-25T03:00:00Z&z=2.0&output_format=application/json
----
Trajectory request:
[source]
----
GET /collections/gfs_025_time-isobaric-lat-lon/latest/trajectory/coords=LINESTRING(53.33 4.76 1000 1560507000,51.90 3.17 400 1560507600,51.8 2.24 400 1560508200,50.74 -3.48 0 1560508500,51.75 2.20 500 1560510240,51.69 1.41 800 1560510960,51.49 0.48 1000 1560511560)&output_format=application/json
----

==== Links section 

The links section caused problems when developing code to parse the metadata with developers having to add logic to avoid getting stuck in recursive loops.  Most would have preferred to use the Restful approach of content negotiation to achieve the same effect.

==== Verbosity 

The number of navigation steps and levels in the API was raised by some of the developers, but they did accept that several of the steps could be skipped once a user had identified the collection that gave the required data.  

- This issue could also be reduced by providing a better discovery process for data parameters.

==== Combination of Multiple and Single requests

Whilst the ability to request multiple points (and multiple polygons) with a single request was seen as useful, the JSON schema of the data returned was different (MultiPoint and MultiPolygon return coverage collections) and not correctly described by the OpenApi documentation.  

- This could be resolved by splitting the requests out into separate individual location and multiple location query types.

===== Data format

The prototype only supported coverageJSON as an output format and all involved in the hackathon were able to parse the results returned but this was a very limited test and in the time available the users were only able to utilise the point query timeseries results so further evaluation is required.